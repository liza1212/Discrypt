{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25e799a5-29ad-4ad3-b778-a574107f584d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (4.39.3)\n",
      "Requirement already satisfied: filelock in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[torch]) (3.13.4)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[torch]) (0.15.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[torch]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[torch]) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[torch]) (0.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[torch]) (23.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[torch]) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[torch]) (4.66.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[torch]) (0.29.2)\n",
      "Requirement already satisfied: torch in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[torch]) (2.2.2)\n",
      "Requirement already satisfied: psutil in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.8)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.11.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.2.0)\n",
      "Requirement already satisfied: sympy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: jinja2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch->transformers[torch]) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch->transformers[torch]) (11.0.2.54)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch->transformers[torch]) (2.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch->transformers[torch]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch->transformers[torch]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch->transformers[torch]) (2.19.3)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch->transformers[torch]) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch->transformers[torch]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch->transformers[torch]) (12.1.0.106)\n",
      "Requirement already satisfied: networkx in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch->transformers[torch]) (3.2.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->transformers[torch]) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->transformers[torch]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->transformers[torch]) (3.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: accelerator in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (2024.3.8.dev1)\n",
      "Requirement already satisfied: bottle<0.13,>=0.12.7 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from accelerator) (0.12.25)\n",
      "Requirement already satisfied: setproctitle>=1.1.8 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from accelerator) (1.3.3)\n",
      "Requirement already satisfied: waitress>=1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from accelerator) (3.0.0)\n",
      "Requirement already satisfied: torch in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: sympy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: networkx in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: fsspec in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: filelock in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (3.13.4)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]\n",
    "!pip install -U accelerator\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f355a78-fe78-4a6c-8ff7-0974a7a83b0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (2.18.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: xxhash in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: aiohttp in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets) (3.9.4)\n",
      "Requirement already satisfied: pandas in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: packaging in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets) (2024.2.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: multiprocess in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: filelock in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets) (3.13.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets) (0.22.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from huggingface-hub>=0.19.4->datasets) (4.11.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.2.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0271936f-afb8-42ea-a832-c6b6ec7dd544",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (0.4.1)\n",
      "Requirement already satisfied: rouge_score in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (0.1.2)\n",
      "Requirement already satisfied: responses<0.19 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: pandas in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from evaluate) (2.18.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from evaluate) (0.22.2)\n",
      "Requirement already satisfied: multiprocess in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: packaging in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from evaluate) (23.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from evaluate) (2024.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from evaluate) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: dill in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: nltk in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: absl-py in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\n",
      "Requirement already satisfied: filelock in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.13.4)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.9.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nltk->rouge_score) (2023.12.25)\n",
      "Requirement already satisfied: click in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nltk->rouge_score) (1.4.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas->evaluate) (2.8.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0558ad0e-16db-44e3-991d-aebd27b7d746",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source_text', 'target_text', 'privacy_mask', 'span_labels', 'mbert_text_tokens', 'mbert_bio_labels', 'id', 'language', 'set'],\n",
       "        num_rows: 177677\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['source_text', 'target_text', 'privacy_mask', 'span_labels', 'mbert_text_tokens', 'mbert_bio_labels', 'id', 'language', 'set'],\n",
       "        num_rows: 47728\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "masking_dataset = load_dataset(\"ai4privacy/pii-masking-300k\")\n",
    "\n",
    "masking_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "211dda5d-5578-4354-b84f-19861c53db9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_training_dataset = masking_dataset[\"train\"].remove_columns(['privacy_mask', 'span_labels', 'mbert_text_tokens', 'mbert_bio_labels', 'id', 'set']).filter(lambda x: x[\"language\"] == \"English\")\n",
    "new_evaluation_dataset = masking_dataset[\"validation\"].remove_columns(['privacy_mask', 'span_labels', 'mbert_text_tokens', 'mbert_bio_labels', 'id','set']).filter(lambda x: x[\"language\"] == \"English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1b1c9f8-3a37-47d0-bec2-5ba92d7ffa85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "overall_dataset = datasets.DatasetDict({\"train\": new_training_dataset,\"test\":new_evaluation_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99b86df1-ef4f-48f2-a6ae-d63c6fddcd5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source_text', 'target_text', 'language'],\n",
       "        num_rows: 29908\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['source_text', 'target_text', 'language'],\n",
       "        num_rows: 7946\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51fd3005-972e-464a-940c-bb286376c52f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d8fdfff1f74fc593c69ab56f19d30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daf993f4-fef5-46ee-b741-960d3cb26ffe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "push_to_hub() missing 1 required positional argument: 'repo_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_283/2829602327.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moverall_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_to_hub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: push_to_hub() missing 1 required positional argument: 'repo_id'"
     ]
    }
   ],
   "source": [
    "overall_dataset.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6efb89d-e4c1-4156-9cc5-742944f4ee23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487b2ed75eb74475b725c59ea76c8b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089db1f524af48268342bc6e9f87d2c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41643a1a656243d18991693c11a401ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9820d036-d18d-466b-9935-5e827a73fc64",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "convert to Train[{text, target}] for training t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef0564c4-73d3-4e4e-98c0-1a9feb2f87dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = \"mask PII: \"\n",
    "def preprocessing_function_for_dataset(dataset):\n",
    "    changed_input = [prefix + doc for doc in dataset[\"source_text\"]]\n",
    "    model_inputs = tokenizer(changed_input, max_length = 1024, truncation = True)\n",
    "\n",
    "    labels = tokenizer(dataset[\"target_text\"], max_length = 1024, truncation = True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b23ff042-c026-4f93-9497-79ab07438c51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source_text', 'target_text', 'privacy_mask', 'span_labels', 'mbert_text_tokens', 'mbert_bio_labels', 'id', 'language', 'set'],\n",
       "    num_rows: 177677\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masking_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0525b501-3d08-4f3c-a555-d6bc8280bc9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_training_dataset = masking_dataset[\"train\"].remove_columns(['privacy_mask', 'span_labels', 'mbert_text_tokens', 'mbert_bio_labels', 'id', 'language', 'set'])\n",
    "new_evaluation_dataset = masking_dataset[\"validation\"].remove_columns(['privacy_mask', 'span_labels', 'mbert_text_tokens', 'mbert_bio_labels', 'id', 'language', 'set'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d24e2b8-1e15-41db-886d-78ab88a2362e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afbfff29b7994ae7b70eecb665bb8186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/47728 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_training_dataset = new_training_dataset.map(preprocessing_function_for_dataset, batched = True)\n",
    "tokenized_validation_dataset = new_evaluation_dataset.map(preprocessing_function_for_dataset, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9f6800c-fd7d-4bca-8535-d965b6d2f562",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source_text': 'Subject: Group Messaging for Admissions Process\\n\\nGood morning, everyone,\\n\\nI hope this message finds you well. As we continue our admissions processes, I would like to update you on the latest developments and key information. Please find below the timeline for our upcoming meetings:\\n\\n- wynqvrh053 - Meeting at 10:20am\\n- luka.burg - Meeting at 21\\n- qahil.wittauer - Meeting at quarter past 13\\n- gholamhossein.ruschke - Meeting at 9:47 PM\\n- pdmjrsyoz1460 ',\n",
       " 'target_text': 'Subject: Group Messaging for Admissions Process\\n\\nGood morning, everyone,\\n\\nI hope this message finds you well. As we continue our admissions processes, I would like to update you on the latest developments and key information. Please find below the timeline for our upcoming meetings:\\n\\n- [USERNAME] - Meeting at [TIME]\\n- [USERNAME] - Meeting at [TIME]\\n- [USERNAME] - Meeting at [TIME]\\n- [USERNAME] - Meeting at [TIME]\\n- [USERNAME] ',\n",
       " 'input_ids': [8181,\n",
       "  3,\n",
       "  4111,\n",
       "  196,\n",
       "  10,\n",
       "  19237,\n",
       "  10,\n",
       "  1531,\n",
       "  6598,\n",
       "  5855,\n",
       "  21,\n",
       "  22100,\n",
       "  7,\n",
       "  10272,\n",
       "  1804,\n",
       "  1379,\n",
       "  6,\n",
       "  921,\n",
       "  6,\n",
       "  27,\n",
       "  897,\n",
       "  48,\n",
       "  1569,\n",
       "  12902,\n",
       "  25,\n",
       "  168,\n",
       "  5,\n",
       "  282,\n",
       "  62,\n",
       "  916,\n",
       "  69,\n",
       "  7209,\n",
       "  7,\n",
       "  2842,\n",
       "  6,\n",
       "  27,\n",
       "  133,\n",
       "  114,\n",
       "  12,\n",
       "  2270,\n",
       "  25,\n",
       "  30,\n",
       "  8,\n",
       "  1251,\n",
       "  11336,\n",
       "  11,\n",
       "  843,\n",
       "  251,\n",
       "  5,\n",
       "  863,\n",
       "  253,\n",
       "  666,\n",
       "  8,\n",
       "  13618,\n",
       "  21,\n",
       "  69,\n",
       "  3,\n",
       "  4685,\n",
       "  4677,\n",
       "  10,\n",
       "  3,\n",
       "  18,\n",
       "  3,\n",
       "  25269,\n",
       "  1824,\n",
       "  208,\n",
       "  52,\n",
       "  107,\n",
       "  3076,\n",
       "  519,\n",
       "  3,\n",
       "  18,\n",
       "  9198,\n",
       "  44,\n",
       "  335,\n",
       "  10,\n",
       "  1755,\n",
       "  265,\n",
       "  3,\n",
       "  18,\n",
       "  3,\n",
       "  40,\n",
       "  1598,\n",
       "  9,\n",
       "  5,\n",
       "  4824,\n",
       "  3,\n",
       "  18,\n",
       "  9198,\n",
       "  44,\n",
       "  1401,\n",
       "  3,\n",
       "  18,\n",
       "  3,\n",
       "  1824,\n",
       "  9,\n",
       "  107,\n",
       "  173,\n",
       "  5,\n",
       "  7820,\n",
       "  17,\n",
       "  12668,\n",
       "  3,\n",
       "  18,\n",
       "  9198,\n",
       "  44,\n",
       "  2893,\n",
       "  657,\n",
       "  1179,\n",
       "  3,\n",
       "  18,\n",
       "  3,\n",
       "  122,\n",
       "  2831,\n",
       "  265,\n",
       "  11982,\n",
       "  7,\n",
       "  2455,\n",
       "  5,\n",
       "  52,\n",
       "  14220,\n",
       "  1050,\n",
       "  3,\n",
       "  18,\n",
       "  9198,\n",
       "  44,\n",
       "  668,\n",
       "  10,\n",
       "  4177,\n",
       "  3246,\n",
       "  3,\n",
       "  18,\n",
       "  3,\n",
       "  102,\n",
       "  26,\n",
       "  51,\n",
       "  354,\n",
       "  52,\n",
       "  7,\n",
       "  63,\n",
       "  32,\n",
       "  172,\n",
       "  2534,\n",
       "  3328,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [19237,\n",
       "  10,\n",
       "  1531,\n",
       "  6598,\n",
       "  5855,\n",
       "  21,\n",
       "  22100,\n",
       "  7,\n",
       "  10272,\n",
       "  1804,\n",
       "  1379,\n",
       "  6,\n",
       "  921,\n",
       "  6,\n",
       "  27,\n",
       "  897,\n",
       "  48,\n",
       "  1569,\n",
       "  12902,\n",
       "  25,\n",
       "  168,\n",
       "  5,\n",
       "  282,\n",
       "  62,\n",
       "  916,\n",
       "  69,\n",
       "  7209,\n",
       "  7,\n",
       "  2842,\n",
       "  6,\n",
       "  27,\n",
       "  133,\n",
       "  114,\n",
       "  12,\n",
       "  2270,\n",
       "  25,\n",
       "  30,\n",
       "  8,\n",
       "  1251,\n",
       "  11336,\n",
       "  11,\n",
       "  843,\n",
       "  251,\n",
       "  5,\n",
       "  863,\n",
       "  253,\n",
       "  666,\n",
       "  8,\n",
       "  13618,\n",
       "  21,\n",
       "  69,\n",
       "  3,\n",
       "  4685,\n",
       "  4677,\n",
       "  10,\n",
       "  3,\n",
       "  18,\n",
       "  784,\n",
       "  11927,\n",
       "  11840,\n",
       "  4369,\n",
       "  908,\n",
       "  3,\n",
       "  18,\n",
       "  9198,\n",
       "  44,\n",
       "  784,\n",
       "  382,\n",
       "  15382,\n",
       "  908,\n",
       "  3,\n",
       "  18,\n",
       "  784,\n",
       "  11927,\n",
       "  11840,\n",
       "  4369,\n",
       "  908,\n",
       "  3,\n",
       "  18,\n",
       "  9198,\n",
       "  44,\n",
       "  784,\n",
       "  382,\n",
       "  15382,\n",
       "  908,\n",
       "  3,\n",
       "  18,\n",
       "  784,\n",
       "  11927,\n",
       "  11840,\n",
       "  4369,\n",
       "  908,\n",
       "  3,\n",
       "  18,\n",
       "  9198,\n",
       "  44,\n",
       "  784,\n",
       "  382,\n",
       "  15382,\n",
       "  908,\n",
       "  3,\n",
       "  18,\n",
       "  784,\n",
       "  11927,\n",
       "  11840,\n",
       "  4369,\n",
       "  908,\n",
       "  3,\n",
       "  18,\n",
       "  9198,\n",
       "  44,\n",
       "  784,\n",
       "  382,\n",
       "  15382,\n",
       "  908,\n",
       "  3,\n",
       "  18,\n",
       "  784,\n",
       "  11927,\n",
       "  11840,\n",
       "  4369,\n",
       "  908,\n",
       "  1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_training_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "882af57c-ade0-410e-a72b-a8d5ef81be79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer, model=\"t5-small\", return_tensors = \"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daa6f4a8-cd9c-45bd-9f5d-d885d7cadb78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df1816b0-8f7b-4eac-a537-86c7cf549263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99dcdd04-cfcf-4282-a8b7-59d0ce56f882",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44842347-528d-4228-82c0-99b55d379cc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    decoded_logits = tokenizer.batch_decode(logits, skip_special_tokens = True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens = True)\n",
    "\n",
    "    result = rouge.compute(predictions = decoded_logits, references = decoded_labels, use_stemmer = True)\n",
    "    return {key:round(value, 4) for key, value in result.items()}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43899bff-8a24-4106-bb3d-fc5d547ebb46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir = \"new_output\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate = 2e-5,\n",
    "    per_device_train_batch_size = 10,\n",
    "    per_device_eval_batch_size = 10,\n",
    "    weight_decay = 0.01,\n",
    "    num_train_epochs = 2,\n",
    "    predict_with_generate = True,\n",
    "    save_total_limit = 3,\n",
    "    fp16 = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a2dcc1c-ddc7-49f8-866e-380acc4a2724",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.14.336, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_training_dataset,\n",
    "    eval_dataset = tokenized_validation_dataset,\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = data_collator,\n",
    "    compute_metrics = compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3465cf8-6d49-4000-843b-68edd020e9a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35536' max='35536' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35536/35536 2:27:38, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.062800</td>\n",
       "      <td>0.033757</td>\n",
       "      <td>0.223700</td>\n",
       "      <td>0.184800</td>\n",
       "      <td>0.223200</td>\n",
       "      <td>0.223200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.049400</td>\n",
       "      <td>0.028046</td>\n",
       "      <td>0.224500</td>\n",
       "      <td>0.186200</td>\n",
       "      <td>0.224100</td>\n",
       "      <td>0.224100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=35536, training_loss=0.0971784194757787, metrics={'train_runtime': 8860.1574, 'train_samples_per_second': 40.107, 'train_steps_per_second': 4.011, 'total_flos': 2.176859660088115e+16, 'train_loss': 0.0971784194757787, 'epoch': 2.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d55e7d-730e-4189-b89a-7a5d9d4a8670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "201525ce-3f8b-4ced-81cd-a7ed4aba2c21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824a6c7cc72846d2abc7ace3d2bd04f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c6ee33b0c94e238e71d4955bed9a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939e6ff1f18f47b88af5a9177508dfdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/aprab/new_output/commit/cec9736c463807db12dd0210a6895cc92c310749', commit_message='End of training', commit_description='', oid='cec9736c463807db12dd0210a6895cc92c310749', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "023e7dbf-a75c-4b85-bb54-f00578a97f75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f3e52ae-2eff-4fa7-92a9-18b0495a3b5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unknown task fillmask, available tasks are ['audio-classification', 'automatic-speech-recognition', 'conversational', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-feature-extraction', 'image-segmentation', 'image-to-image', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text-to-audio', 'text-to-speech', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_73/2465955589.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummarizer_sec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fillmask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"aprab/new_output\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m             )\n\u001b[1;32m    858\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0mnormalized_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpipeline_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0mpipeline_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"impl\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mcheck_task\u001b[0;34m(task)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m     \"\"\"\n\u001b[0;32m--> 543\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPIPELINE_REGISTRY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mcheck_task\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m   1279\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid translation task {task}, use 'translation_XX_to_YY' format\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1281\u001b[0;31m         raise KeyError(\n\u001b[0m\u001b[1;32m   1282\u001b[0m             \u001b[0;34mf\"Unknown task {task}, available tasks are {self.get_supported_tasks() + ['translation_XX_to_YY']}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m         )\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unknown task fillmask, available tasks are ['audio-classification', 'automatic-speech-recognition', 'conversational', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-feature-extraction', 'image-segmentation', 'image-to-image', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text-to-audio', 'text-to-speech', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']\""
     ]
    }
   ],
   "source": [
    "summarizer_sec = pipeline(\"fillmask\", model = \"aprab/new_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecc8145d-75e2-468d-b2e5-a091303a816b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but your input_length is only 142. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=71)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'Subject: Group Messaging for Admissions Process Good morning, everyone, I hope this message finds you well. As we continue our admissions processes, I would like to update you on the latest developments and key information. Please find below the timeline for our upcoming meetings: - wynqvrh053 - Meeting at [TIME] - [USERNAME]'}]\n"
     ]
    }
   ],
   "source": [
    "output_string = summarizer_sec(\"Subject: Group Messaging for Admissions Process\\n\\nGood morning, everyone,\\n\\nI hope this message finds you well. As we continue our admissions processes, I would like to update you on the latest developments and key information. Please find below the timeline for our upcoming meetings:\\n\\n- wynqvrh053 - Meeting at 10:20am\\n- luka.burg - Meeting at 21\\n- qahil.wittauer - Meeting at quarter past 13\\n- gholamhossein.ruschke - Meeting at 9:47 PM\\n- pdmjrsyoz1460\")\n",
    "print(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bafcb4be-7a6f-4e9e-9686-1babc3d7afda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but your input_length is only 18. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'you will be given your meeting ID at 5:00PM at google.com . if you have a meeting ID, please contact us for more information.'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer_sec(\"You will be given your meeting ID at 5:00PM at google.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ae0905-d5a9-481e-9069-0b3ae32b7b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> Group Messaging for Admissions Process Good morning, everyone, I hope this message finds you well. As we continue our admissions processes, I would like to update you on the latest developments and key information. Please find below the timeline for our upcoming meetings: - [USERNAME] - Meeting at [TIME] - [USERNAME] - Meeting at [TIME] - [USERNAME] - Meeting at [TIME] - [USERNAME]</s>'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mask_prediction(text):\n",
    "    text = \"mask PII\" + text\n",
    "    tokenized = tokenizer([text], truncation = True, padding=\"longest\", return_tensors = 'pt')\n",
    "    #tokenized = {k: v.to('cuda') for k, v in tokenized.items()}\n",
    "    tokenized_result = model.generate(**tokenized, max_length = 128)\n",
    "    tokenized_result = tokenized_result.to('cpu')\n",
    "    predicted_summary = tokenizer.decode(tokenized_result[0])\n",
    "    return predicted_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4fa6c431-e989-4eb2-8d92-ec24865f1237",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<pad> On the video sharing platform for educational content, a lively discussion unfolded among users from different locales within the UK. The comment thread began with [USERNAME] expressing admiration for the video's insightful content, followed by [USERNAME] adding a clarification on a complex topic. [USERNAME] chimed in with a question for clarification, an</s>\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_prediction(masking_dataset[\"validation\"][0][\"source_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16816bd5-d299-4025-a870-aaca203f35ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"On the video sharing platform for educational content, a lively discussion unfolded among users from different locales within the UK.\\n\\nThe comment thread began with [USERNAME] expressing admiration for the video's insightful content, followed by [USERNAME] adding a clarification on a complex topic. [USERNAME] chimed in with a question for clarification, an\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masking_dataset[\"validation\"][0][\"target_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d577b98c-3f92-4f11-887d-8c6e1413f3d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> Mark Davis works at [COUNTRY] [STREET], located at [BUILDING], [STREET], [CITY], [STATE].</s>'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_prediction(\"Mark Davis works at XYZ Corporation, located at 789 Maple Avenue, Boston, MA 02115.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3802bb34-6f4f-4c8f-9fb2-e0bca5824418",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<pad> Sarah Williams' date of birth is [BOD].</s>\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_prediction(\"Sarah Williams' date of birth is June 15, 1990.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "16370326-a8ff-4e69-8ccb-d96af6da800a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> [LASTNAME1] [LASTNAME2] lives at [BUILDING], [STREET], [CITY], [STATE] 62701</s>'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_prediction(\"Emily Johnson lives at 456 Elm Street, Springfield, IL 62701\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a36b15dd-f4bb-450f-9ac0-1b7f56bb7a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<pad> Candidate Suitability for Admission Date: [DATE] Time: [TIME] Location: [POSTCODE] Candidate A: - Sex: [SEX] - Date of Birth: [BOD] - Email: [EMAIL] - ID Card Number: [IDCARD] - Driver's License: [DRIVERLICENSE] - IP Address: [IP] - Password: [PASS]</s>\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_prediction(\"Evaluation Report: Candidate Suitability for Admission Date: 29/06/2013 Time: 7:59 PM \\\n",
    "Location: CM21 Candidate A: - Sex: M - Date of Birth: October/97 - Email: MVC@tutanota.com  \\\n",
    "- ID Card Number: RF69601MW - Driver's License: MASCU910077MV815 - \\\n",
    "IP Address: 7836:3dcf:9edf:692:fd5f:4de5:a9d6:da24 - Password: Be~o}.zq8^1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0904808e-d40c-4284-ad0d-adb9d6dc89df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> <unk>/instructor> <unk>instructor> <unk>name> <unk>title>[TITLE]<unk>/title> <unk>social_number>[SOCIALNUMBER]<unk>/social_number> <unk>id_card>[IDCARD]<unk>/id_card> <unk>/name> <unk>/instructor> <unk>instructor> <unk>name> <unk>title>[TITLE]<unk>/title> <unk>social_number>[SOCIALNUMBER]<unk>/social_number'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_prediction(\"</instructor> <instructor> <name> <title>Mayoress</title> <social_number>3341955554</social_number> <id_card>TY41985ST</id_card> </name> </instructor> <instructor> <name> <title>Father</title> <social_number>299.463.5913</social_number> <id_card>EA38031TP</id_card> </name> </instructor> <instructor>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ad340b4-de3b-4c61-ac2c-e41832ac674b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> [GIVENNAME1], your social security number is [SOCIALNUMBER]</s>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_prediction(\"Hello david, your social security number is 123123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd0917ce-dbd1-44e3-8c30-471e23869339",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> liza, your social security number is 123123</s>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_prediction(\"Hello liza, your social security number is 123123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "595894e7-9f06-4b39-9b2b-12bd6ed7cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"new_output/checkpoint-35500\", return_dict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4761e81-8f09-4ae3-abad-58a9c82f1449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<pad> [LASTNAME1]'s phone Number is [TEL]</s>\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_prediction(\"John Carter's phone Number is 9840304234\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c26ba33e-4e07-42fa-aa69-769485c53a64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.10.3\n",
      "  latest version: 24.3.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/studio-lab-user/.conda/envs/default\n",
      "\n",
      "  added / updated specs:\n",
      "    - zip\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2024.2.2   |       hbcca054_0         152 KB  conda-forge\n",
      "    certifi-2024.2.2           |     pyhd8ed1ab_0         157 KB  conda-forge\n",
      "    openssl-3.2.1              |       hd590300_1         2.7 MB  conda-forge\n",
      "    zip-3.0                    |       hd590300_3         173 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         3.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  zip                conda-forge/linux-64::zip-3.0-hd590300_3\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2023.7.22-hbcca054_0 --> 2024.2.2-hbcca054_0\n",
      "  certifi                            2023.7.22-pyhd8ed1ab_0 --> 2024.2.2-pyhd8ed1ab_0\n",
      "  openssl                                  3.1.2-hd590300_0 --> 3.2.1-hd590300_1\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "ca-certificates-2024 | 152 KB    | ##################################### | 100% \n",
      "zip-3.0              | 173 KB    | ##################################### | 100% \n",
      "openssl-3.2.1        | 2.7 MB    | ##################################### | 100% \n",
      "certifi-2024.2.2     | 157 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_158/3922614779.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conda install -y -c conda-forge zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mzip\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "!conda install -y -c conda-forge zip\n",
    "zip -r -X  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c0191fe-a584-425a-823b-f81c93c398eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: new_output/ (stored 0%)\n",
      "  adding: new_output/checkpoint-34500/ (stored 0%)\n",
      "  adding: new_output/checkpoint-34500/config.json (deflated 62%)\n",
      "  adding: new_output/checkpoint-34500/generation_config.json (deflated 29%)\n",
      "  adding: new_output/checkpoint-34500/model.safetensors"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (deflated 9%)\n",
      "  adding: new_output/checkpoint-34500/tokenizer_config.json (deflated 95%)\n",
      "  adding: new_output/checkpoint-34500/special_tokens_map.json (deflated 85%)\n",
      "  adding: new_output/checkpoint-34500/tokenizer.json (deflated 74%)\n",
      "  adding: new_output/checkpoint-34500/training_args.bin (deflated 51%)\n",
      "  adding: new_output/checkpoint-34500/optimizer.pt (deflated 7%)\n",
      "  adding: new_output/checkpoint-34500/scheduler.pt (deflated 55%)\n",
      "  adding: new_output/checkpoint-34500/rng_state.pth (deflated 25%)\n",
      "  adding: new_output/checkpoint-34500/trainer_state.json (deflated 78%)\n",
      "  adding: new_output/checkpoint-35000/ (stored 0%)\n",
      "  adding: new_output/checkpoint-35000/config.json (deflated 62%)\n",
      "  adding: new_output/checkpoint-35000/generation_config.json (deflated 29%)\n",
      "  adding: new_output/checkpoint-35000/model.safetensors (deflated 9%)\n",
      "  adding: new_output/checkpoint-35000/tokenizer_config.json (deflated 95%)\n",
      "  adding: new_output/checkpoint-35000/special_tokens_map.json (deflated 85%)\n",
      "  adding: new_output/checkpoint-35000/tokenizer.json (deflated 74%)\n",
      "  adding: new_output/checkpoint-35000/training_args.bin (deflated 51%)\n",
      "  adding: new_output/checkpoint-35000/optimizer.pt (deflated 7%)\n",
      "  adding: new_output/checkpoint-35000/scheduler.pt (deflated 56%)\n",
      "  adding: new_output/checkpoint-35000/rng_state.pth (deflated 25%)\n",
      "  adding: new_output/checkpoint-35000/trainer_state.json (deflated 78%)\n",
      "  adding: new_output/checkpoint-35500/ (stored 0%)\n",
      "  adding: new_output/checkpoint-35500/config.json (deflated 62%)\n",
      "  adding: new_output/checkpoint-35500/generation_config.json (deflated 29%)\n",
      "  adding: new_output/checkpoint-35500/model.safetensors (deflated 9%)\n",
      "  adding: new_output/checkpoint-35500/tokenizer_config.json (deflated 95%)\n",
      "  adding: new_output/checkpoint-35500/special_tokens_map.json (deflated 85%)\n",
      "  adding: new_output/checkpoint-35500/tokenizer.json (deflated 74%)\n",
      "  adding: new_output/checkpoint-35500/training_args.bin (deflated 51%)\n",
      "  adding: new_output/checkpoint-35500/optimizer.pt (deflated 7%)\n",
      "  adding: new_output/checkpoint-35500/scheduler.pt (deflated 56%)\n",
      "  adding: new_output/checkpoint-35500/rng_state.pth (deflated 25%)\n",
      "  adding: new_output/checkpoint-35500/trainer_state.json (deflated 78%)\n",
      "  adding: new_output/config.json (deflated 62%)\n",
      "  adding: new_output/generation_config.json (deflated 29%)\n",
      "  adding: new_output/model.safetensors (deflated 9%)\n",
      "  adding: new_output/tokenizer_config.json (deflated 95%)\n",
      "  adding: new_output/special_tokens_map.json (deflated 85%)\n",
      "  adding: new_output/tokenizer.json (deflated 74%)\n",
      "  adding: new_output/training_args.bin (deflated 51%)\n",
      "  adding: new_output/README.md (deflated 50%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r -X output.zip new_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2876e360-94b3-4d48-907b-ae20340f4440",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> [TITLE] [PASS] used to go to Kathmandu when I was a kid, my home is there.</s>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_prediction(\"I used to go to Kathmandu when I was a kid, my home is there.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e91bbb4-3c40-446f-90fc-28029b269bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
